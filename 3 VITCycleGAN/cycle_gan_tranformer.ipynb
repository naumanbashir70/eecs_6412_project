{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZY4wzGluPY",
        "outputId": "03e5cd7a-9bba-4aaa-c9b1-b7498f59529b"
      },
      "outputs": [],
      "source": [
        "!conda activate nauman_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Requiremements**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conda install pytorch=1.12.0 torchvision=0.13.0 cudatoolkit=11.3.1 -c pytorch\n",
        "# conda install albumentations=1.2.1 -c conda-forge\n",
        "# conda install einops=0.4.1 -c conda-forge\n",
        "# conda install torchsummary=1.5.1 -c ravelbio\n",
        "# conda install tqdm=4.64.0\n",
        "# conda install scikit-image=0.18.3\n",
        "# conda install scikit-learn=1.1.1\n",
        "# conda install torchmetrics=0.9.3 -c conda-forge"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Downloading**\n",
        "For training and evaluation we used the BraTS Dataset from RSNA-ASNR-MICCAI BraTS Continuous Evaluation Challenge:\n",
        "https://www.synapse.org/#!Synapse:syn51156910/wiki/622351\n",
        "\n",
        "1. Download the data\n",
        "2. Convert 3d .nii.gz file to 2d\n",
        "    2a. We used two modalities. i) T1 ii) T1 Contrast\n",
        "3. Resize the images to 256 256, (Original images in 3D are 240 240 155)\n",
        "4. We have placed the covnerted 2d resized files here:\n",
        "https://drive.google.com/file/d/1hXJ8CP6BgJz2bFM1OF2LmGtc3VvRgZhS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import itertools\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converting T1 3D Nifti images to 2D PNG images \n",
        "\n",
        "folder = '/local/data0/home/naumanb/Codes/4_SwinUnetR_BraTS_2023/BraTS2023/TrainingData'\n",
        "\n",
        "for root, dir, files in os.walk(folder):\n",
        "    for file in files:\n",
        "        im = os.path.join(root, file)\n",
        "        # print(file)\n",
        "\n",
        "        # if file.endswith('t1c.nii.gz'):\n",
        "        if file.endswith('t1n.nii.gz'):\n",
        "            print(file)\n",
        "            img = os.path.join(root, file)\n",
        "            img = nib.load(img)\n",
        "            img = img.get_data().astype(np.float32)\n",
        "            img_data = np.rot90(img, 3)\n",
        "\n",
        "            plt.imshow(img_data[:, :, 77], cmap='gray')\n",
        "            plt.axis('off')\n",
        "            # Save as PNG\n",
        "            plt.savefig('/local/data0/home/naumanb/Codes/8_Cx_GAN/data/t1n/' +\n",
        "                        file+'.png', bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "            # Show the plot (optional)\n",
        "            # plt.show()\n",
        "\n",
        "    # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converting T1-Contrat 3D Nifti images to 2D PNG images\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "import nibabel as nib\n",
        "\n",
        "folder = '/local/data0/home/naumanb/Codes/4_SwinUnetR_BraTS_2023/BraTS2023/TrainingData'\n",
        "\n",
        "for root, dir, files in os.walk(folder):\n",
        "    for file in files:\n",
        "        im = os.path.join(root, file)\n",
        "\n",
        "        if file.endswith('t1c.nii.gz'):\n",
        "            print(file)\n",
        "            img_path = os.path.join(root, file)\n",
        "            img = nib.load(img_path)\n",
        "            img_data = img.get_data().astype(np.float32)\n",
        "            img_data = np.rot90(img_data, 3)\n",
        "\n",
        "\n",
        "            plt.imshow(img_data[:, :, 77], cmap='gray')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Save as PNG\n",
        "            output_path = '/local/data0/home/naumanb/Codes/8_Cx_GAN/data/t1c/' + file + '.png'\n",
        "            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
        "            # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resizing the images to 256x256\n",
        "\n",
        "#Resize the image to 256,256\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "path = \"/local/data0/home/naumanb/Codes/8_Cx_GAN/data/t1c/\"\n",
        "dirs = os.listdir( path )\n",
        "out = \"/local/data0/home/naumanb/Codes/8_Cx_GAN/data/t1c_r/\"\n",
        "\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(path+item)\n",
        "            print(item)\n",
        "            print(f)\n",
        "            imResize = im.resize((256,256), Image.ANTIALIAS)\n",
        "            imResize.save(out+item+'.png', 'PNG', quality=100)\n",
        "\n",
        "resize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import UnidentifiedImageError\n",
        "import PIL\n",
        "\n",
        "class ABDataset(Dataset):\n",
        "    def __init__(self, root_a, root_b=None, transform=None):\n",
        "        self.root_a = root_a\n",
        "        self.root_b = root_b\n",
        "        self.transform = transform\n",
        "\n",
        "        self.a_images = os.listdir(root_a)  # t1 images\n",
        "        self.b_images = os.listdir(root_b) if root_b else []  # t1c images\n",
        "        self.length_dataset = max(len(self.a_images), len(self.b_images))\n",
        "        self.a_len = len(self.a_images)\n",
        "        self.b_len = len(self.b_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.root_b is not None:\n",
        "            a_img = self.a_images[index % self.a_len]\n",
        "            a_path = os.path.join(self.root_a, a_img)\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    a_img = np.array(Image.open(a_path).convert(\"RGB\"))\n",
        "                    break\n",
        "                except (PIL.UnidentifiedImageError, OSError):\n",
        "                    # skip non-image files\n",
        "                    index = (index + 1) % self.length_dataset\n",
        "                    a_img = self.a_images[index % self.a_len]\n",
        "                    a_path = os.path.join(self.root_a, a_img)\n",
        "\n",
        "            b_img = self.b_images[index % self.b_len]\n",
        "            b_path = os.path.join(self.root_b, b_img)\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    b_img = np.array(Image.open(b_path).convert(\"RGB\"))\n",
        "                    break\n",
        "                except (PIL.UnidentifiedImageError, OSError):\n",
        "                    # skip non-image files\n",
        "                    index = (index + 1) % self.length_dataset\n",
        "                    b_img = self.b_images[index % self.b_len]\n",
        "                    b_path = os.path.join(self.root_b, b_img)\n",
        "\n",
        "            # Apply min-max normalization to images\n",
        "            a_img = (a_img - np.min(a_img)) / (np.max(a_img) - np.min(a_img))\n",
        "            b_img = (b_img - np.min(b_img)) / (np.max(b_img) - np.min(b_img))\n",
        "\n",
        "            if self.transform:\n",
        "                augmentations = self.transform(image0=a_img, image=b_img)\n",
        "                a_img = augmentations[\"image0\"]\n",
        "                b_img = augmentations[\"image\"]\n",
        "\n",
        "            return a_img, b_img\n",
        "\n",
        "        elif self.root_b is None:\n",
        "            a_img = self.a_images[index % self.a_len]\n",
        "            a_path = os.path.join(self.root_a, a_img)\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    a_img = np.array(Image.open(a_path).convert(\"RGB\"))\n",
        "                    break\n",
        "                except (PIL.UnidentifiedImageError, OSError):\n",
        "                    # skip non-image files\n",
        "                    index = (index + 1) % self.length_dataset\n",
        "                    a_img = self.a_images[index % self.a_len]\n",
        "                    a_path = os.path.join(self.root_a, a_img)\n",
        "\n",
        "            # Apply min-max normalization to images\n",
        "            a_img = (a_img - np.min(a_img)) / (np.max(a_img) - np.min(a_img))\n",
        "\n",
        "            if self.transform:\n",
        "                augmentations = self.transform(image=a_img)\n",
        "                a_img = augmentations[\"image\"]\n",
        "\n",
        "            return a_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (patches): ImgPatches(\n",
            "    (patch_embed): Conv2d(3, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
            "  )\n",
            "  (TransformerEncoder): TransformerEncoder(\n",
            "    (Encoder_Blocks): ModuleList(\n",
            "      (0): Encoder_Block(\n",
            "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
            "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "          (out): Sequential(\n",
            "            (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (1): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (droprateout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up_blocks): ModuleList(\n",
            "    (0): ConvolutionBlockG(\n",
            "      (convolution): Sequential(\n",
            "        (0): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ConvolutionBlockG(\n",
            "      (convolution): Sequential(\n",
            "        (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ConvolutionBlockG(\n",
            "      (convolution): Sequential(\n",
            "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (last): Conv2d(128, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
            ")\n",
            "torch.Size([1, 3, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "# Generator \n",
        "\n",
        "import torch\n",
        "from cyclegan_tranformer import Generator, Discriminator\n",
        "gen = Generator(width=256, height=256).to(torch.device(\"cuda\"))\n",
        "    \n",
        "print(gen)\n",
        "tensor = torch.randn((1, 3, 256, 256)).to(torch.device(\"cuda\"))\n",
        "output = gen(tensor)\n",
        "print(output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator output shape: torch.Size([1, 3, 256, 256])\n",
            "Discriminator(\n",
            "  (initial): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (down_blocks): ModuleList(\n",
            "    (0): ConvolutionBlockD(\n",
            "      (convolution): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ConvolutionBlockD(\n",
            "      (convolution): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
            "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ConvolutionBlockD(\n",
            "      (convolution): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
            "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (last): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            ")\n",
            "Discriminator output shape: torch.Size([1, 1, 30, 30])\n"
          ]
        }
      ],
      "source": [
        "# Discriminator\n",
        "\n",
        "import torch\n",
        "from cyclegan_tranformer import Generator, Discriminator\n",
        "\n",
        "disc = Discriminator().to(torch.device(\"cuda\"))\n",
        "tensor = torch.randn((1, 3, 256, 256)).to(torch.device(\"cuda\"))\n",
        "gen_output = gen(tensor)\n",
        "print(\"Generator output shape:\", gen_output.shape)\n",
        "print(disc)\n",
        "disc_output = disc(gen_output)\n",
        "print(\"Discriminator output shape:\", disc_output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-19 11:43:42.758876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected GPU: 3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "# from torchsummary import summary\n",
        "from Utils import save_checkpoint, load_checkpoint\n",
        "from cyclegan_tranformer import Generator, Discriminator\n",
        "from torch.utils.tensorboard import SummaryWriter \n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "writer = SummaryWriter(log_dir=\"logs\")\n",
        "\n",
        "TRAIN_DIR = \"datasets/brats/train\"\n",
        "path = \"Results\"\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "LAMBDA_IDENTITY = 10\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 4\n",
        "NUM_EPOCHS = 500\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "CHECKPOINT_GEN_A = f\"{path}/gena.pth.tar\"\n",
        "CHECKPOINT_GEN_B = f\"{path}/genb.pth.tar\"\n",
        "CHECKPOINT_DISC_A = f\"{path}/disca.pth.tar\"\n",
        "CHECKPOINT_DISC_B = f\"{path}/discb.pth.tar\"\n",
        "count = 0\n",
        "\n",
        "\n",
        "gpu_index = 2  # for 4th GPU\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(f\"cuda:{gpu_index}\")\n",
        "    print(f\"Selected GPU: {gpu_index}\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(\"Results\"):\n",
        "    os.mkdir(\"Results\")\n",
        "    os.mkdir(\"Results/Generated from T1C\")\n",
        "    os.mkdir(\"Results/Generated from T1\")\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "        ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "\n",
        "def train_fn(disc_A, disc_B, gen_A, gen_B, loader, opt_disc, opt_gen, l1, mse,  d_scaler, g_scaler, epoch):\n",
        "    global count\n",
        "    avg_dloss = 0\n",
        "    avg_gloss = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for idx, (a, b) in enumerate(loop):\n",
        "        a = a.to(DEVICE)\n",
        "        b = b.to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_a = gen_A(b)\n",
        "            D_A_real = disc_A(a)\n",
        "            D_A_fake = disc_A(fake_a.detach())\n",
        "            D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))\n",
        "            D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake))\n",
        "            D_A_loss = D_A_real_loss + D_A_fake_loss\n",
        "\n",
        "            fake_b = gen_B(a)\n",
        "            D_B_real = disc_B(b)\n",
        "            D_B_fake = disc_B(fake_b.detach())\n",
        "            D_B_real_loss = mse(D_B_real, torch.ones_like(D_B_real))\n",
        "            D_B_fake_loss = mse(D_B_fake, torch.zeros_like(D_B_fake))\n",
        "            D_B_loss = D_B_real_loss + D_B_fake_loss\n",
        "\n",
        "            D_loss = (D_A_loss + D_B_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            D_A_fake = disc_A(fake_a)\n",
        "            D_B_fake = disc_B(fake_b)\n",
        "            loss_G_A = mse(D_A_fake, torch.ones_like(D_A_fake))\n",
        "            loss_G_B = mse(D_B_fake, torch.ones_like(D_B_fake))\n",
        "\n",
        "            cycle_b = gen_B(fake_a)\n",
        "            cycle_a = gen_A(fake_b)\n",
        "            cycle_b_loss = l1(b, cycle_b)\n",
        "            cycle_a_loss = l1(a, cycle_a)\n",
        "\n",
        "            identity_b = gen_B(b)\n",
        "            identity_a = gen_A(a)\n",
        "            identity_b_loss = l1(b, identity_b)\n",
        "            identity_a_loss = l1(a, identity_a)\n",
        "\n",
        "            G_loss = (\n",
        "                loss_G_B\n",
        "                + loss_G_A\n",
        "                + cycle_b_loss * LAMBDA_CYCLE\n",
        "                + cycle_a_loss * LAMBDA_CYCLE\n",
        "                + identity_a_loss * LAMBDA_IDENTITY\n",
        "                + identity_b_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "            avg_dloss += D_loss.item()\n",
        "            avg_gloss += G_loss.item()\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "        \n",
        "        writer.add_scalar(\"Discriminator Loss\", D_loss.item(), epoch * len(loader) + idx)\n",
        "        writer.add_scalar(\"Generator Loss\", G_loss.item(), epoch * len(loader) + idx)\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            save_image(fake_a*0.5+0.5, f\"{path}/Generated from T1c/{count}_fake.png\")\n",
        "            save_image(fake_b*0.5+0.5, f\"{path}/Generated from T1/{count}_fake.png\")\n",
        "            save_image(b*0.5+0.5, f\"{path}/Generated from T1c/{count}_real.png\")\n",
        "            save_image(a*0.5+0.5, f\"{path}/Generated from T1/{count}_real.png\")\n",
        "            count += 1\n",
        "        loop.set_postfix(epoch=epoch+1, loss_g=avg_gloss/(idx+1), loss_d=avg_dloss/(idx+1))\n",
        "\n",
        "\n",
        "def main():\n",
        "    disc_A = Discriminator().to(DEVICE)\n",
        "    disc_B = Discriminator().to(DEVICE)\n",
        "    gen_A = Generator(width=IMAGE_WIDTH, height=IMAGE_HEIGHT).to(DEVICE)\n",
        "    gen_B = Generator(width=IMAGE_WIDTH, height=IMAGE_HEIGHT).to(DEVICE)\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_A.parameters()) + list(disc_B.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_A.parameters()) + list(gen_B.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_A, gen_A, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_B, gen_B, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISC_A, disc_A, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISC_B, disc_B, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    dataset = ABDataset(\n",
        "        root_a=TRAIN_DIR+\"/t1c_r\", root_b=TRAIN_DIR+\"/t1n_r\", transform=transforms\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(disc_A, disc_B, gen_A, gen_B, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler, epoch)\n",
        "\n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_A, opt_gen, filename=CHECKPOINT_GEN_A)\n",
        "            save_checkpoint(gen_B, opt_gen, filename=CHECKPOINT_GEN_B)\n",
        "            save_checkpoint(disc_A, opt_disc, filename=CHECKPOINT_DISC_A)\n",
        "            save_checkpoint(disc_B, opt_disc, filename=CHECKPOINT_DISC_B)\n",
        "            \n",
        "    writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected GPU: 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "# from torchsummary import summary\n",
        "from Utils import save_checkpoint, load_checkpoint\n",
        "from cyclegan_tranformer import Generator, Discriminator\n",
        "from torch.utils.tensorboard import SummaryWriter \n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "writer = SummaryWriter(log_dir=\"logs\")\n",
        "\n",
        "TRAIN_DIR = \"datasets/brats/train\"\n",
        "path = \"Results\"\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "LAMBDA_IDENTITY = 10\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 4\n",
        "NUM_EPOCHS = 500\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "CHECKPOINT_GEN_A = f\"{path}/gena.pth.tar\"\n",
        "CHECKPOINT_GEN_B = f\"{path}/genb.pth.tar\"\n",
        "CHECKPOINT_DISC_A = f\"{path}/disca.pth.tar\"\n",
        "CHECKPOINT_DISC_B = f\"{path}/discb.pth.tar\"\n",
        "count = 0\n",
        "\n",
        "\n",
        "gpu_index = 2  # for 4th GPU\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(f\"cuda:{gpu_index}\")\n",
        "    print(f\"Selected GPU: {gpu_index}\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(\"Results\"):\n",
        "    os.mkdir(\"Results\")\n",
        "    os.mkdir(\"Results/Generated from T1C\")\n",
        "    os.mkdir(\"Results/Generated from T1\")\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "        ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "\n",
        "def train_fn(disc_A, disc_B, gen_A, gen_B, loader, opt_disc, opt_gen, l1, mse,  d_scaler, g_scaler, epoch):\n",
        "    global count\n",
        "    avg_dloss = 0\n",
        "    avg_gloss = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for idx, (a, b) in enumerate(loop):\n",
        "        a = a.to(DEVICE)\n",
        "        b = b.to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_a = gen_A(b)\n",
        "            D_A_real = disc_A(a)\n",
        "            D_A_fake = disc_A(fake_a.detach())\n",
        "            D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))\n",
        "            D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake))\n",
        "            D_A_loss = D_A_real_loss + D_A_fake_loss\n",
        "\n",
        "            fake_b = gen_B(a)\n",
        "            D_B_real = disc_B(b)\n",
        "            D_B_fake = disc_B(fake_b.detach())\n",
        "            D_B_real_loss = mse(D_B_real, torch.ones_like(D_B_real))\n",
        "            D_B_fake_loss = mse(D_B_fake, torch.zeros_like(D_B_fake))\n",
        "            D_B_loss = D_B_real_loss + D_B_fake_loss\n",
        "\n",
        "            D_loss = (D_A_loss + D_B_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            D_A_fake = disc_A(fake_a)\n",
        "            D_B_fake = disc_B(fake_b)\n",
        "            loss_G_A = mse(D_A_fake, torch.ones_like(D_A_fake))\n",
        "            loss_G_B = mse(D_B_fake, torch.ones_like(D_B_fake))\n",
        "\n",
        "            cycle_b = gen_B(fake_a)\n",
        "            cycle_a = gen_A(fake_b)\n",
        "            cycle_b_loss = l1(b, cycle_b)\n",
        "            cycle_a_loss = l1(a, cycle_a)\n",
        "\n",
        "            identity_b = gen_B(b)\n",
        "            identity_a = gen_A(a)\n",
        "            identity_b_loss = l1(b, identity_b)\n",
        "            identity_a_loss = l1(a, identity_a)\n",
        "\n",
        "            G_loss = (\n",
        "                loss_G_B\n",
        "                + loss_G_A\n",
        "                + cycle_b_loss * LAMBDA_CYCLE\n",
        "                + cycle_a_loss * LAMBDA_CYCLE\n",
        "                + identity_a_loss * LAMBDA_IDENTITY\n",
        "                + identity_b_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "            avg_dloss += D_loss.item()\n",
        "            avg_gloss += G_loss.item()\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "        \n",
        "        writer.add_scalar(\"Discriminator Loss\", D_loss.item(), epoch * len(loader) + idx)\n",
        "        writer.add_scalar(\"Generator Loss\", G_loss.item(), epoch * len(loader) + idx)\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            save_image(fake_a*0.5+0.5, f\"{path}/Generated from T1c/{count}_fake.png\")\n",
        "            save_image(fake_b*0.5+0.5, f\"{path}/Generated from T1/{count}_fake.png\")\n",
        "            save_image(b*0.5+0.5, f\"{path}/Generated from T1c/{count}_real.png\")\n",
        "            save_image(a*0.5+0.5, f\"{path}/Generated from T1/{count}_real.png\")\n",
        "            count += 1\n",
        "        loop.set_postfix(epoch=epoch+1, loss_g=avg_gloss/(idx+1), loss_d=avg_dloss/(idx+1))\n",
        "\n",
        "\n",
        "def main():\n",
        "    disc_A = Discriminator().to(DEVICE)\n",
        "    disc_B = Discriminator().to(DEVICE)\n",
        "    gen_A = Generator(width=IMAGE_WIDTH, height=IMAGE_HEIGHT).to(DEVICE)\n",
        "    gen_B = Generator(width=IMAGE_WIDTH, height=IMAGE_HEIGHT).to(DEVICE)\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_A.parameters()) + list(disc_B.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_A.parameters()) + list(gen_B.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_A, gen_A, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_B, gen_B, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISC_A, disc_A, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISC_B, disc_B, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    dataset = ABDataset(\n",
        "        root_a=TRAIN_DIR+\"/t1c_r\", root_b=TRAIN_DIR+\"/t1n_r\", transform=transforms\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(disc_A, disc_B, gen_A, gen_B, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler, epoch)\n",
        "\n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_A, opt_gen, filename=CHECKPOINT_GEN_A)\n",
        "            save_checkpoint(gen_B, opt_gen, filename=CHECKPOINT_GEN_B)\n",
        "            save_checkpoint(disc_A, opt_disc, filename=CHECKPOINT_DISC_A)\n",
        "            save_checkpoint(disc_B, opt_disc, filename=CHECKPOINT_DISC_B)\n",
        "            \n",
        "    writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 126/126 [01:12<00:00,  1.73it/s, epoch=1, loss_d=0.232, loss_g=3.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=2, loss_d=0.11, loss_g=1.54] \n",
            "100%|██████████| 126/126 [01:17<00:00,  1.63it/s, epoch=3, loss_d=0.0485, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:17<00:00,  1.63it/s, epoch=4, loss_d=0.0695, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.64it/s, epoch=5, loss_d=0.0617, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=6, loss_d=0.143, loss_g=1.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=7, loss_d=0.237, loss_g=0.572]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=8, loss_d=0.232, loss_g=0.584]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=9, loss_d=0.227, loss_g=0.594]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=10, loss_d=0.223, loss_g=0.603]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=11, loss_d=0.219, loss_g=0.611]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=12, loss_d=0.216, loss_g=0.619]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=13, loss_d=0.213, loss_g=0.627]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=14, loss_d=0.209, loss_g=0.634]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=15, loss_d=0.206, loss_g=0.642]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=16, loss_d=0.203, loss_g=0.649]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=17, loss_d=0.2, loss_g=0.656]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=18, loss_d=0.197, loss_g=0.663]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=19, loss_d=0.195, loss_g=0.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=20, loss_d=0.192, loss_g=0.677]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=21, loss_d=0.189, loss_g=0.684]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=22, loss_d=0.186, loss_g=0.691]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=23, loss_d=0.184, loss_g=0.698]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=24, loss_d=0.181, loss_g=0.705]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=25, loss_d=0.179, loss_g=0.712]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=26, loss_d=0.176, loss_g=0.719]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=27, loss_d=0.174, loss_g=0.726]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=28, loss_d=0.171, loss_g=0.733]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=29, loss_d=0.169, loss_g=0.739]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=30, loss_d=0.167, loss_g=0.746]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=31, loss_d=0.164, loss_g=0.753]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=32, loss_d=0.162, loss_g=0.76] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=33, loss_d=0.16, loss_g=0.767]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=34, loss_d=0.157, loss_g=0.774]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=35, loss_d=0.155, loss_g=0.781]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=36, loss_d=0.153, loss_g=0.787]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=37, loss_d=0.151, loss_g=0.794]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=38, loss_d=0.149, loss_g=0.801]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=39, loss_d=0.146, loss_g=0.808]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=40, loss_d=0.144, loss_g=0.815]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=41, loss_d=0.142, loss_g=0.822]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=42, loss_d=0.14, loss_g=0.828]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=43, loss_d=0.138, loss_g=0.835]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=44, loss_d=0.136, loss_g=0.842]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=45, loss_d=0.134, loss_g=0.849]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=46, loss_d=0.132, loss_g=0.856]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=47, loss_d=0.13, loss_g=0.863]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=48, loss_d=0.128, loss_g=0.87] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=49, loss_d=0.126, loss_g=0.876]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=50, loss_d=0.125, loss_g=0.883]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=51, loss_d=0.123, loss_g=0.89] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=52, loss_d=0.121, loss_g=0.897]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=53, loss_d=0.119, loss_g=0.904]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=54, loss_d=0.117, loss_g=0.911]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=55, loss_d=0.115, loss_g=0.917]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=56, loss_d=0.114, loss_g=0.924]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=57, loss_d=0.112, loss_g=0.931]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=58, loss_d=0.11, loss_g=0.938]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=59, loss_d=0.109, loss_g=0.945]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=60, loss_d=0.107, loss_g=0.951]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=61, loss_d=0.105, loss_g=0.958]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=62, loss_d=0.104, loss_g=0.965]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=63, loss_d=0.102, loss_g=0.972]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=64, loss_d=0.101, loss_g=0.979]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=65, loss_d=0.099, loss_g=0.985] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=66, loss_d=0.0974, loss_g=0.992]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=67, loss_d=0.0959, loss_g=0.999]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=68, loss_d=0.0944, loss_g=1.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=69, loss_d=0.0929, loss_g=1.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=70, loss_d=0.0915, loss_g=1.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=71, loss_d=0.09, loss_g=1.03]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=72, loss_d=0.0886, loss_g=1.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=73, loss_d=0.0872, loss_g=1.04]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=74, loss_d=0.0858, loss_g=1.05]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=75, loss_d=0.0844, loss_g=1.05]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=76, loss_d=0.0831, loss_g=1.06]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=77, loss_d=0.0818, loss_g=1.07]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=78, loss_d=0.0804, loss_g=1.07]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=79, loss_d=0.0792, loss_g=1.08]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=80, loss_d=0.0779, loss_g=1.08]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=81, loss_d=0.0766, loss_g=1.09]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=82, loss_d=0.0754, loss_g=1.1]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=83, loss_d=0.0742, loss_g=1.1]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=84, loss_d=0.0729, loss_g=1.11]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=85, loss_d=0.0718, loss_g=1.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=86, loss_d=0.0706, loss_g=1.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=87, loss_d=0.0694, loss_g=1.13]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=88, loss_d=0.0683, loss_g=1.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=89, loss_d=0.0672, loss_g=1.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=90, loss_d=0.0661, loss_g=1.15]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=91, loss_d=0.065, loss_g=1.16] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=92, loss_d=0.0639, loss_g=1.16]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=93, loss_d=0.0628, loss_g=1.17]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=94, loss_d=0.0618, loss_g=1.17]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=95, loss_d=0.0608, loss_g=1.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=96, loss_d=0.0597, loss_g=1.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=97, loss_d=0.0587, loss_g=1.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=98, loss_d=0.0578, loss_g=1.2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=99, loss_d=0.0568, loss_g=1.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=100, loss_d=0.0558, loss_g=1.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=101, loss_d=0.0549, loss_g=1.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=102, loss_d=0.054, loss_g=1.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=103, loss_d=0.053, loss_g=1.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=104, loss_d=0.0521, loss_g=1.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=105, loss_d=0.0512, loss_g=1.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=106, loss_d=0.0504, loss_g=1.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=107, loss_d=0.0495, loss_g=1.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=108, loss_d=0.0487, loss_g=1.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=109, loss_d=0.0478, loss_g=1.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=110, loss_d=0.047, loss_g=1.27] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=111, loss_d=0.0462, loss_g=1.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=112, loss_d=0.0454, loss_g=1.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=113, loss_d=0.0446, loss_g=1.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=114, loss_d=0.0439, loss_g=1.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=115, loss_d=0.0431, loss_g=1.3]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=116, loss_d=0.0423, loss_g=1.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=117, loss_d=0.0416, loss_g=1.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=118, loss_d=0.0409, loss_g=1.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=119, loss_d=0.0402, loss_g=1.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=120, loss_d=0.0395, loss_g=1.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=121, loss_d=0.0388, loss_g=1.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=122, loss_d=0.0381, loss_g=1.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=123, loss_d=0.0374, loss_g=1.35]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=124, loss_d=0.0368, loss_g=1.35]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=125, loss_d=0.0361, loss_g=1.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=126, loss_d=0.0356, loss_g=1.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=127, loss_d=0.0349, loss_g=1.37]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=128, loss_d=0.0342, loss_g=1.37]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=129, loss_d=0.0336, loss_g=1.38]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=130, loss_d=0.033, loss_g=1.38] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=131, loss_d=0.0325, loss_g=1.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=132, loss_d=0.0319, loss_g=1.4] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=133, loss_d=0.0313, loss_g=1.4]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=134, loss_d=0.0307, loss_g=1.41]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=135, loss_d=0.0302, loss_g=1.41]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=136, loss_d=0.0297, loss_g=1.42]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=137, loss_d=0.0291, loss_g=1.42]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=138, loss_d=0.0286, loss_g=1.43]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=139, loss_d=0.0281, loss_g=1.43]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=140, loss_d=0.0276, loss_g=1.44]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=141, loss_d=0.0271, loss_g=1.44]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=142, loss_d=0.0266, loss_g=1.45]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=143, loss_d=0.0261, loss_g=1.45]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=144, loss_d=0.0256, loss_g=1.46]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=145, loss_d=0.0252, loss_g=1.46]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=146, loss_d=0.0247, loss_g=1.47]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=147, loss_d=0.0243, loss_g=1.47]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=148, loss_d=0.0238, loss_g=1.48]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=149, loss_d=0.0234, loss_g=1.48]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=150, loss_d=0.023, loss_g=1.49]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=151, loss_d=0.0226, loss_g=1.49]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=152, loss_d=0.0221, loss_g=1.49]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=153, loss_d=0.0218, loss_g=1.5]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=154, loss_d=0.0214, loss_g=1.5]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=155, loss_d=0.021, loss_g=1.51]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=156, loss_d=0.0206, loss_g=1.51]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=157, loss_d=0.0202, loss_g=1.52]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=158, loss_d=0.0198, loss_g=1.52]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=159, loss_d=0.0195, loss_g=1.53]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=160, loss_d=0.02, loss_g=1.53]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=161, loss_d=0.0187, loss_g=1.54]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=162, loss_d=0.0184, loss_g=1.54]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=163, loss_d=0.0181, loss_g=1.54]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=164, loss_d=0.0177, loss_g=1.55]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=165, loss_d=0.0174, loss_g=1.55]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=166, loss_d=0.0171, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=167, loss_d=0.0168, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=168, loss_d=0.0164, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=169, loss_d=0.0161, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=170, loss_d=0.0158, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=171, loss_d=0.0155, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=172, loss_d=0.0153, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=173, loss_d=0.015, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=174, loss_d=0.0147, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=175, loss_d=0.0144, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=176, loss_d=0.0141, loss_g=1.6]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=177, loss_d=0.0146, loss_g=1.6]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=178, loss_d=0.0136, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=179, loss_d=0.0134, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=180, loss_d=0.0131, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=181, loss_d=0.013, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=182, loss_d=0.0126, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=183, loss_d=0.0124, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=184, loss_d=0.0122, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=185, loss_d=0.0119, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=186, loss_d=0.0117, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=187, loss_d=0.0115, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=188, loss_d=0.0113, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=189, loss_d=0.011, loss_g=1.65] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=190, loss_d=0.0108, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=191, loss_d=0.0106, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=192, loss_d=0.0104, loss_g=1.66]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=193, loss_d=0.0102, loss_g=1.66]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=194, loss_d=0.01, loss_g=1.66]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=195, loss_d=0.00985, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=196, loss_d=0.00966, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=197, loss_d=0.00947, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=198, loss_d=0.0093, loss_g=1.68] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=199, loss_d=0.00912, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=200, loss_d=0.00894, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=201, loss_d=0.00877, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=202, loss_d=0.00861, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=203, loss_d=0.00844, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=204, loss_d=0.00828, loss_g=1.7]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=205, loss_d=0.00812, loss_g=1.7]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=206, loss_d=0.00796, loss_g=1.7]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=207, loss_d=0.00781, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=208, loss_d=0.00766, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=209, loss_d=0.00751, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=210, loss_d=0.00737, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=211, loss_d=0.00723, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=212, loss_d=0.00709, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=213, loss_d=0.00695, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=214, loss_d=0.00682, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=215, loss_d=0.00669, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=216, loss_d=0.00656, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=217, loss_d=0.00643, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=218, loss_d=0.00631, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=219, loss_d=0.00618, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=220, loss_d=0.00607, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=221, loss_d=0.00595, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=222, loss_d=0.00583, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=223, loss_d=0.00572, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=224, loss_d=0.00561, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=225, loss_d=0.0055, loss_g=1.76] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=226, loss_d=0.00539, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=227, loss_d=0.00529, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=228, loss_d=0.00519, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=229, loss_d=0.00508, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=230, loss_d=0.00499, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=231, loss_d=0.00489, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=232, loss_d=0.00479, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=233, loss_d=0.0047, loss_g=1.78] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=234, loss_d=0.00461, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=235, loss_d=0.00452, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=236, loss_d=0.00443, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=237, loss_d=0.00435, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=238, loss_d=0.00426, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=239, loss_d=0.00418, loss_g=1.8]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=240, loss_d=0.0041, loss_g=1.8]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=241, loss_d=0.00402, loss_g=1.8]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=242, loss_d=0.00394, loss_g=1.8]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=243, loss_d=0.00386, loss_g=1.8]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=244, loss_d=0.00378, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=245, loss_d=0.00371, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=246, loss_d=0.00364, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=247, loss_d=0.00357, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=248, loss_d=0.0035, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=249, loss_d=0.00343, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=250, loss_d=0.00336, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=251, loss_d=0.00339, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=252, loss_d=0.00323, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=253, loss_d=0.00317, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=254, loss_d=0.0031, loss_g=1.83] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=255, loss_d=0.00306, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=256, loss_d=0.00298, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=257, loss_d=0.00292, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=258, loss_d=0.00287, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=259, loss_d=0.00281, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=260, loss_d=0.00276, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=261, loss_d=0.00271, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=262, loss_d=0.00267, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=263, loss_d=0.0026, loss_g=1.85] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=264, loss_d=0.00254, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=265, loss_d=0.00249, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=266, loss_d=0.00244, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=267, loss_d=0.0024, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=268, loss_d=0.00235, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=269, loss_d=0.0023, loss_g=1.86] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=270, loss_d=0.00226, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=271, loss_d=0.00221, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=272, loss_d=0.00217, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=273, loss_d=0.00228, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=274, loss_d=0.00208, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=275, loss_d=0.00204, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=276, loss_d=0.002, loss_g=1.87]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=277, loss_d=0.00196, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=278, loss_d=0.00192, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=279, loss_d=0.00189, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=280, loss_d=0.00185, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=281, loss_d=0.00181, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=282, loss_d=0.00178, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=283, loss_d=0.00174, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=284, loss_d=0.00171, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=285, loss_d=0.00167, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=286, loss_d=0.00164, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=287, loss_d=0.00161, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=288, loss_d=0.00157, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=289, loss_d=0.00154, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=290, loss_d=0.00151, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=291, loss_d=0.00148, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=292, loss_d=0.00145, loss_g=1.9]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=293, loss_d=0.00142, loss_g=1.9]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=294, loss_d=0.00139, loss_g=1.9]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=295, loss_d=0.00137, loss_g=1.9]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=296, loss_d=0.00134, loss_g=1.9]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=297, loss_d=0.00131, loss_g=1.9]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=298, loss_d=0.00129, loss_g=1.9]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=299, loss_d=0.00126, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=300, loss_d=0.00124, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=301, loss_d=0.00121, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=302, loss_d=0.00119, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=303, loss_d=0.00116, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=304, loss_d=0.00114, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=305, loss_d=0.00112, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=306, loss_d=0.00109, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=307, loss_d=0.00107, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=308, loss_d=0.00105, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=309, loss_d=0.00103, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=310, loss_d=0.00101, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=311, loss_d=0.00101, loss_g=1.92] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=312, loss_d=0.00097, loss_g=1.92] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=313, loss_d=0.000951, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=314, loss_d=0.000932, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=315, loss_d=0.00211, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=316, loss_d=0.000895, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=317, loss_d=0.000878, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=318, loss_d=0.00086, loss_g=1.93] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=319, loss_d=0.000843, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=320, loss_d=0.000826, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=321, loss_d=0.000809, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=322, loss_d=0.000793, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=323, loss_d=0.000777, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=324, loss_d=0.000762, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=325, loss_d=0.000746, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=326, loss_d=0.000731, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=327, loss_d=0.000717, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=328, loss_d=0.000702, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=329, loss_d=0.000688, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=330, loss_d=0.000674, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=331, loss_d=0.000661, loss_g=1.94]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=332, loss_d=0.000648, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=333, loss_d=0.000634, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=334, loss_d=0.000622, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=335, loss_d=0.000609, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=336, loss_d=0.000597, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=337, loss_d=0.000585, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=338, loss_d=0.000573, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=339, loss_d=0.000562, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=340, loss_d=0.00055, loss_g=1.95] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=341, loss_d=0.000539, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=342, loss_d=0.000528, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=343, loss_d=0.000518, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=344, loss_d=0.000507, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=345, loss_d=0.000497, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=346, loss_d=0.000487, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=347, loss_d=0.000477, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=348, loss_d=0.000468, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=349, loss_d=0.000458, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=350, loss_d=0.000449, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=351, loss_d=0.00044, loss_g=1.96] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=352, loss_d=0.000431, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=353, loss_d=0.000422, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=354, loss_d=0.000414, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=355, loss_d=0.000405, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=356, loss_d=0.000398, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=357, loss_d=0.000389, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=358, loss_d=0.000381, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=359, loss_d=0.000374, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=360, loss_d=0.000366, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=361, loss_d=0.000359, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=362, loss_d=0.000352, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=363, loss_d=0.000344, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=364, loss_d=0.000337, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=365, loss_d=0.000331, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=366, loss_d=0.000324, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=367, loss_d=0.000317, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=368, loss_d=0.000311, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=369, loss_d=0.000305, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=370, loss_d=0.000544, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=371, loss_d=0.000299, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=372, loss_d=0.00029, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=373, loss_d=0.000285, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=374, loss_d=0.000281, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=375, loss_d=0.000276, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=376, loss_d=0.000272, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=377, loss_d=0.000268, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=378, loss_d=0.000262, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=379, loss_d=0.000259, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=380, loss_d=0.000254, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=381, loss_d=0.000249, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=382, loss_d=0.000245, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=383, loss_d=0.00024, loss_g=1.98] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=384, loss_d=0.000236, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=385, loss_d=0.000232, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=386, loss_d=0.00116, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=387, loss_d=0.000224, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=388, loss_d=0.00022, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=389, loss_d=0.000215, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=390, loss_d=0.000211, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=391, loss_d=0.000207, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=392, loss_d=0.000204, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=393, loss_d=0.0002, loss_g=1.99] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=394, loss_d=0.000196, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=395, loss_d=0.000192, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=396, loss_d=0.000188, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=397, loss_d=0.000185, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=398, loss_d=0.000181, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=399, loss_d=0.000178, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=400, loss_d=0.000174, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=401, loss_d=0.000171, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=402, loss_d=0.000167, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=403, loss_d=0.000164, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=404, loss_d=0.000161, loss_g=2]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=405, loss_d=0.000158, loss_g=2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=406, loss_d=0.000154, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=407, loss_d=0.000151, loss_g=2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=408, loss_d=0.000148, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=409, loss_d=0.000145, loss_g=2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=410, loss_d=0.000142, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=411, loss_d=0.000139, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=412, loss_d=0.000137, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=413, loss_d=0.000134, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=414, loss_d=0.000131, loss_g=2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=415, loss_d=0.000129, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=416, loss_d=0.000126, loss_g=2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=417, loss_d=0.000123, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=418, loss_d=0.000121, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=419, loss_d=0.000119, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=420, loss_d=0.000116, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=421, loss_d=0.000114, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=422, loss_d=0.000112, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=423, loss_d=0.000109, loss_g=2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=424, loss_d=0.000107, loss_g=2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=425, loss_d=0.000105, loss_g=2]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=426, loss_d=0.000103, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=427, loss_d=0.000101, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=428, loss_d=9.86e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=429, loss_d=9.66e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=430, loss_d=9.46e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=431, loss_d=9.27e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=432, loss_d=9.08e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=433, loss_d=8.9e-5, loss_g=2.01] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=434, loss_d=8.72e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=435, loss_d=8.55e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=436, loss_d=8.37e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=437, loss_d=8.21e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=438, loss_d=8.03e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=439, loss_d=7.87e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=440, loss_d=7.71e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=441, loss_d=7.55e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=442, loss_d=7.4e-5, loss_g=2.01] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=443, loss_d=7.25e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=444, loss_d=7.1e-5, loss_g=2.01] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=445, loss_d=6.95e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=446, loss_d=6.81e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=447, loss_d=6.68e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=448, loss_d=6.54e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=449, loss_d=6.41e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=450, loss_d=6.28e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=451, loss_d=6.15e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=452, loss_d=6.03e-5, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=453, loss_d=5.98e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=454, loss_d=5.78e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=455, loss_d=6.22e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=456, loss_d=5.57e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=457, loss_d=5.46e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=458, loss_d=5.35e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=459, loss_d=5.24e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=460, loss_d=5.14e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=461, loss_d=5.04e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=462, loss_d=4.94e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=463, loss_d=4.84e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=464, loss_d=4.74e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=465, loss_d=4.65e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=466, loss_d=4.56e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=467, loss_d=4.46e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=468, loss_d=4.37e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=469, loss_d=4.29e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=470, loss_d=4.2e-5, loss_g=2.02] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=471, loss_d=4.12e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=472, loss_d=4.03e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=473, loss_d=3.95e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=474, loss_d=3.87e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=475, loss_d=3.79e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=476, loss_d=3.72e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=477, loss_d=3.64e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=478, loss_d=3.66e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=479, loss_d=3.5e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=480, loss_d=3.43e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=481, loss_d=3.36e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=482, loss_d=3.29e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=483, loss_d=3.22e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=484, loss_d=3.16e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=485, loss_d=3.09e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=486, loss_d=3.03e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=487, loss_d=2.97e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=488, loss_d=2.91e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=489, loss_d=2.89e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=490, loss_d=2.79e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=491, loss_d=2.73e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=492, loss_d=2.68e-5, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=493, loss_d=2.62e-5, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=494, loss_d=2.57e-5, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=495, loss_d=2.52e-5, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=496, loss_d=2.47e-5, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=497, loss_d=2.42e-5, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=498, loss_d=2.37e-5, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=499, loss_d=2.32e-5, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.67it/s, epoch=500, loss_d=2.27e-5, loss_g=2.03]\n"
          ]
        }
      ],
      "source": [
        "# Train Normalization\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 126/126 [01:13<00:00,  1.73it/s, epoch=1, loss_d=0.367, loss_g=4.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=2, loss_d=0.377, loss_g=2.6] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=3, loss_d=0.377, loss_g=2.58]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=4, loss_d=0.436, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=5, loss_d=0.447, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=6, loss_d=0.443, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=7, loss_d=0.433, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=8, loss_d=0.443, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=9, loss_d=0.442, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=10, loss_d=0.451, loss_g=1.7] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=11, loss_d=0.417, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=12, loss_d=0.425, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=13, loss_d=0.436, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=14, loss_d=0.435, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=15, loss_d=0.418, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=16, loss_d=0.434, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=17, loss_d=0.43, loss_g=1.66] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=18, loss_d=0.425, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=19, loss_d=0.429, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=20, loss_d=0.429, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=21, loss_d=0.425, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=22, loss_d=0.428, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=23, loss_d=0.429, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=24, loss_d=0.428, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=25, loss_d=0.425, loss_g=1.6]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=26, loss_d=0.426, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=27, loss_d=0.418, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=28, loss_d=0.425, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=29, loss_d=0.428, loss_g=1.53]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=30, loss_d=0.406, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=31, loss_d=0.384, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=32, loss_d=0.369, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=33, loss_d=0.378, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=34, loss_d=0.375, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=35, loss_d=0.347, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=36, loss_d=0.344, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=37, loss_d=0.377, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=38, loss_d=0.358, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=39, loss_d=0.338, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=40, loss_d=0.329, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=41, loss_d=0.334, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=42, loss_d=0.318, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=43, loss_d=0.304, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=44, loss_d=0.341, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=45, loss_d=0.309, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=46, loss_d=0.326, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=47, loss_d=0.445, loss_g=1.48]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=48, loss_d=0.429, loss_g=1.48]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=49, loss_d=0.417, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=50, loss_d=0.422, loss_g=1.5] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=51, loss_d=0.353, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=52, loss_d=0.355, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=53, loss_d=0.286, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=54, loss_d=0.281, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=55, loss_d=0.305, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=56, loss_d=0.279, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=57, loss_d=0.282, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=58, loss_d=0.361, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=59, loss_d=0.414, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=60, loss_d=0.407, loss_g=1.54]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=61, loss_d=0.421, loss_g=1.5] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=62, loss_d=0.408, loss_g=1.55]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=63, loss_d=0.348, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=64, loss_d=0.251, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=65, loss_d=0.247, loss_g=2]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=66, loss_d=0.279, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=67, loss_d=0.253, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=68, loss_d=0.24, loss_g=2]    \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=69, loss_d=0.211, loss_g=2.06]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=70, loss_d=0.279, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=71, loss_d=0.256, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=72, loss_d=0.362, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=73, loss_d=0.377, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=74, loss_d=0.386, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=75, loss_d=0.413, loss_g=1.54]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=76, loss_d=0.362, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=77, loss_d=0.286, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=78, loss_d=0.331, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=79, loss_d=0.385, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=80, loss_d=0.392, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=81, loss_d=0.368, loss_g=1.7] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=82, loss_d=0.29, loss_g=1.89] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=83, loss_d=0.387, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=84, loss_d=0.373, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=85, loss_d=0.136, loss_g=2.53]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=86, loss_d=0.188, loss_g=2.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=87, loss_d=0.173, loss_g=2.15]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=88, loss_d=0.193, loss_g=2.17]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=89, loss_d=0.19, loss_g=2.16] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=90, loss_d=0.256, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=91, loss_d=0.39, loss_g=1.55] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=92, loss_d=0.323, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=93, loss_d=0.335, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=94, loss_d=0.384, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=95, loss_d=0.302, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=96, loss_d=0.422, loss_g=1.46]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=97, loss_d=0.407, loss_g=1.45]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=98, loss_d=0.225, loss_g=2.06]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=99, loss_d=0.106, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=100, loss_d=0.136, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=101, loss_d=0.185, loss_g=2.13]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=102, loss_d=0.362, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=103, loss_d=0.355, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=104, loss_d=0.305, loss_g=1.7] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=105, loss_d=0.245, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=106, loss_d=0.223, loss_g=2.05]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=107, loss_d=0.222, loss_g=2.04]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=108, loss_d=0.186, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=109, loss_d=0.109, loss_g=2.24] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=110, loss_d=0.15, loss_g=2.24] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=111, loss_d=0.207, loss_g=2.05]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=112, loss_d=0.102, loss_g=2.27] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=113, loss_d=0.073, loss_g=2.34] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=114, loss_d=0.247, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=115, loss_d=0.305, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=116, loss_d=0.335, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=117, loss_d=0.106, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=118, loss_d=0.0645, loss_g=2.38]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=119, loss_d=0.0156, loss_g=2.35]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=120, loss_d=0.188, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=121, loss_d=0.262, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=122, loss_d=0.267, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=123, loss_d=0.117, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=124, loss_d=0.312, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=125, loss_d=0.297, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=126, loss_d=0.254, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=127, loss_d=0.18, loss_g=2.29] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=128, loss_d=0.116, loss_g=2.53]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=129, loss_d=0.177, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=130, loss_d=0.081, loss_g=2.35] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=131, loss_d=0.0788, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=132, loss_d=0.0638, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=133, loss_d=0.0269, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=134, loss_d=0.0744, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=135, loss_d=0.0788, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=136, loss_d=0.183, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=137, loss_d=0.155, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=138, loss_d=0.215, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=139, loss_d=0.258, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=140, loss_d=0.223, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=141, loss_d=0.211, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=142, loss_d=0.288, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=143, loss_d=0.102, loss_g=2.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=144, loss_d=0.0951, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=145, loss_d=0.179, loss_g=2.06]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=146, loss_d=0.132, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=147, loss_d=0.0131, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=148, loss_d=0.00313, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=149, loss_d=0.146, loss_g=2.07] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=150, loss_d=0.206, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=151, loss_d=0.223, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=152, loss_d=0.437, loss_g=1.44]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=153, loss_d=0.313, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=154, loss_d=0.0729, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=155, loss_d=0.236, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=156, loss_d=0.182, loss_g=2]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=157, loss_d=0.244, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=158, loss_d=0.211, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=159, loss_d=0.0591, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=160, loss_d=0.0661, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=161, loss_d=0.0122, loss_g=2.35]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=162, loss_d=0.0834, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=163, loss_d=0.113, loss_g=2.12] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=164, loss_d=0.221, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=165, loss_d=0.212, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=166, loss_d=0.0872, loss_g=2.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=167, loss_d=0.17, loss_g=2.04] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=168, loss_d=0.194, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=169, loss_d=0.153, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=170, loss_d=0.0211, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=171, loss_d=0.00827, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=172, loss_d=0.151, loss_g=2.13] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=173, loss_d=0.0241, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=174, loss_d=0.0852, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=175, loss_d=0.238, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=176, loss_d=0.0244, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=177, loss_d=0.0133, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=178, loss_d=0.144, loss_g=2.01] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=179, loss_d=0.237, loss_g=2.04]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=180, loss_d=0.264, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=181, loss_d=0.198, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=182, loss_d=0.164, loss_g=2.05]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=183, loss_d=0.0406, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=184, loss_d=0.0539, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=185, loss_d=0.0091, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=186, loss_d=0.093, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=187, loss_d=0.0445, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=188, loss_d=0.0211, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=189, loss_d=0.0311, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=190, loss_d=0.0404, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=191, loss_d=0.144, loss_g=2.14] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=192, loss_d=0.0488, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=193, loss_d=0.161, loss_g=1.99] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=194, loss_d=0.214, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=195, loss_d=0.255, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=196, loss_d=0.285, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=197, loss_d=0.238, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=198, loss_d=0.191, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=199, loss_d=0.197, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=200, loss_d=0.121, loss_g=2.09]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=201, loss_d=0.254, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=202, loss_d=0.314, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=203, loss_d=0.227, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=204, loss_d=0.119, loss_g=2.06]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=205, loss_d=0.0393, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=206, loss_d=0.0997, loss_g=2.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=207, loss_d=0.251, loss_g=1.83] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=208, loss_d=0.238, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=209, loss_d=0.249, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=210, loss_d=0.244, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=211, loss_d=0.177, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=212, loss_d=0.0243, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=213, loss_d=0.0854, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=214, loss_d=0.254, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=215, loss_d=0.229, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=216, loss_d=0.319, loss_g=1.66]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=217, loss_d=0.143, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=218, loss_d=0.0971, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=219, loss_d=0.232, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=220, loss_d=0.313, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=221, loss_d=0.158, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=222, loss_d=0.0207, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=223, loss_d=0.0193, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=224, loss_d=0.0142, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=225, loss_d=0.143, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=226, loss_d=0.229, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=227, loss_d=0.0697, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=228, loss_d=0.0133, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=229, loss_d=0.0841, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=230, loss_d=0.211, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=231, loss_d=0.228, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=232, loss_d=0.226, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=233, loss_d=0.338, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=234, loss_d=0.455, loss_g=1.17]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=235, loss_d=0.451, loss_g=1.15]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=236, loss_d=0.282, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=237, loss_d=0.314, loss_g=1.66]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=238, loss_d=0.0491, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=239, loss_d=0.0749, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=240, loss_d=0.0854, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=241, loss_d=0.0455, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=242, loss_d=0.03, loss_g=2.27]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=243, loss_d=0.00312, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=244, loss_d=0.205, loss_g=1.94] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=245, loss_d=0.35, loss_g=1.45] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=246, loss_d=0.185, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=247, loss_d=0.0456, loss_g=2.4] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=248, loss_d=0.0558, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=249, loss_d=0.0135, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=250, loss_d=0.123, loss_g=2.07]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=251, loss_d=0.222, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=252, loss_d=0.208, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=253, loss_d=0.27, loss_g=1.72] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=254, loss_d=0.257, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=255, loss_d=0.199, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=256, loss_d=0.214, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=257, loss_d=0.0286, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=258, loss_d=0.168, loss_g=1.96] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=259, loss_d=0.234, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=260, loss_d=0.297, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=261, loss_d=0.181, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=262, loss_d=0.24, loss_g=1.76] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=263, loss_d=0.319, loss_g=1.7] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=264, loss_d=0.365, loss_g=1.49]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=265, loss_d=0.252, loss_g=1.66]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=266, loss_d=0.273, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=267, loss_d=0.167, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=268, loss_d=0.0958, loss_g=2.15]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=269, loss_d=0.0782, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=270, loss_d=0.0166, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=271, loss_d=0.0229, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=272, loss_d=0.141, loss_g=2.12] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=273, loss_d=0.0697, loss_g=2.17]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=274, loss_d=0.0306, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=275, loss_d=0.0277, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=276, loss_d=0.0404, loss_g=2.25] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=277, loss_d=0.146, loss_g=2.09]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=278, loss_d=0.238, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=279, loss_d=0.277, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=280, loss_d=0.271, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=281, loss_d=0.188, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=282, loss_d=0.0622, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=283, loss_d=0.122, loss_g=2.21] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=284, loss_d=0.255, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=285, loss_d=0.123, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=286, loss_d=0.0935, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=287, loss_d=0.0698, loss_g=2.16]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=288, loss_d=0.0279, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=289, loss_d=0.0146, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=290, loss_d=0.0349, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=291, loss_d=0.0141, loss_g=2.27] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=292, loss_d=0.0914, loss_g=2.16]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=293, loss_d=0.197, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=294, loss_d=0.239, loss_g=1.7] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=295, loss_d=0.178, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=296, loss_d=0.0561, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=297, loss_d=0.122, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=298, loss_d=0.0998, loss_g=2.15]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=299, loss_d=0.0559, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=300, loss_d=0.0398, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=301, loss_d=0.226, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=302, loss_d=0.07, loss_g=2.1]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=303, loss_d=0.00393, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=304, loss_d=0.00751, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=305, loss_d=0.00366, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=306, loss_d=0.243, loss_g=1.88]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=307, loss_d=0.125, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=308, loss_d=0.293, loss_g=1.86]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=309, loss_d=0.269, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=310, loss_d=0.26, loss_g=1.66] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=311, loss_d=0.12, loss_g=2.1]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=312, loss_d=0.0336, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=313, loss_d=0.0194, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=314, loss_d=0.258, loss_g=1.84] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=315, loss_d=0.096, loss_g=2.08] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=316, loss_d=0.128, loss_g=2.12]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=317, loss_d=0.0514, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=318, loss_d=0.0628, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=319, loss_d=0.0458, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=320, loss_d=0.0123, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=321, loss_d=0.00634, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=322, loss_d=0.169, loss_g=2.07]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=323, loss_d=0.27, loss_g=1.67] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=324, loss_d=0.119, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=325, loss_d=0.0307, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=326, loss_d=0.016, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=327, loss_d=0.0304, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=328, loss_d=0.0166, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=329, loss_d=0.0285, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=330, loss_d=0.0533, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=331, loss_d=0.0149, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=332, loss_d=0.0207, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=333, loss_d=0.00717, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=334, loss_d=0.00981, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=335, loss_d=0.181, loss_g=1.97] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=336, loss_d=0.234, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=337, loss_d=0.164, loss_g=2.08]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=338, loss_d=0.0265, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=339, loss_d=0.00464, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=340, loss_d=0.00363, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=341, loss_d=0.0174, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=342, loss_d=0.0173, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=343, loss_d=0.0159, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=344, loss_d=0.00984, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=345, loss_d=0.069, loss_g=2.17] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=346, loss_d=0.036, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=347, loss_d=0.0345, loss_g=2.21] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=348, loss_d=0.0122, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=349, loss_d=0.00352, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=350, loss_d=0.00529, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=351, loss_d=0.00701, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=352, loss_d=0.0312, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=353, loss_d=0.0825, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=354, loss_d=0.0651, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=355, loss_d=0.0592, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=356, loss_d=0.00481, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=357, loss_d=0.00245, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=358, loss_d=0.00132, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=359, loss_d=0.00159, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=360, loss_d=0.0104, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=361, loss_d=0.312, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=362, loss_d=0.237, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=363, loss_d=0.227, loss_g=1.7] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=364, loss_d=0.222, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=365, loss_d=0.221, loss_g=1.7] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=366, loss_d=0.2, loss_g=1.75]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=367, loss_d=0.0917, loss_g=2.15]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=368, loss_d=0.0539, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=369, loss_d=0.191, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=370, loss_d=0.177, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=371, loss_d=0.186, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=372, loss_d=0.175, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=373, loss_d=0.0207, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=374, loss_d=0.0113, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=375, loss_d=0.0103, loss_g=2.21] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=376, loss_d=0.0187, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=377, loss_d=0.174, loss_g=2.05] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=378, loss_d=0.263, loss_g=1.66]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=379, loss_d=0.247, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=380, loss_d=0.241, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=381, loss_d=0.236, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=382, loss_d=0.243, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=383, loss_d=0.232, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=384, loss_d=0.232, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=385, loss_d=0.235, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=386, loss_d=0.499, loss_g=1.49]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=387, loss_d=0.404, loss_g=1.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=388, loss_d=0.474, loss_g=0.983]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=389, loss_d=0.463, loss_g=1.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=390, loss_d=0.364, loss_g=1.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=391, loss_d=0.241, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=392, loss_d=0.235, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=393, loss_d=0.416, loss_g=1.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=394, loss_d=0.462, loss_g=1.06]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=395, loss_d=0.463, loss_g=1.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=396, loss_d=0.388, loss_g=1.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=397, loss_d=0.237, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=398, loss_d=0.219, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=399, loss_d=0.235, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=400, loss_d=0.22, loss_g=1.69] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=401, loss_d=0.23, loss_g=1.7]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=402, loss_d=0.243, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=403, loss_d=0.239, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=404, loss_d=0.236, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=405, loss_d=0.235, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=406, loss_d=0.225, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=407, loss_d=0.243, loss_g=1.57]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=408, loss_d=0.228, loss_g=1.69]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=409, loss_d=0.159, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=410, loss_d=0.249, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=411, loss_d=0.196, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=412, loss_d=0.399, loss_g=1.53]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=413, loss_d=0.235, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=414, loss_d=0.233, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=415, loss_d=0.232, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=416, loss_d=0.226, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=417, loss_d=0.223, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=418, loss_d=0.389, loss_g=1.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=419, loss_d=0.454, loss_g=1.06]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=420, loss_d=0.441, loss_g=1.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=421, loss_d=0.451, loss_g=1.1] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=422, loss_d=0.26, loss_g=1.6]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=423, loss_d=0.171, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=424, loss_d=0.168, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=425, loss_d=0.238, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=426, loss_d=0.292, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=427, loss_d=0.46, loss_g=1.13] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=428, loss_d=0.457, loss_g=1.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=429, loss_d=0.423, loss_g=1.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=430, loss_d=0.234, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=431, loss_d=0.235, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=432, loss_d=0.234, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=433, loss_d=0.234, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=434, loss_d=0.231, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=435, loss_d=0.231, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=436, loss_d=0.23, loss_g=1.6]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=437, loss_d=0.227, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=438, loss_d=0.232, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=439, loss_d=0.202, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=440, loss_d=0.226, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=441, loss_d=0.483, loss_g=1.08]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=442, loss_d=0.427, loss_g=1.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=443, loss_d=0.453, loss_g=1.07]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=444, loss_d=0.417, loss_g=1.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=445, loss_d=0.24, loss_g=1.58] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=446, loss_d=0.188, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=447, loss_d=0.238, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=448, loss_d=0.304, loss_g=1.53]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=449, loss_d=0.443, loss_g=1.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=450, loss_d=0.357, loss_g=1.41]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=451, loss_d=0.238, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=452, loss_d=0.223, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=453, loss_d=0.283, loss_g=1.67]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=454, loss_d=0.257, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=455, loss_d=0.272, loss_g=1.51]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=456, loss_d=0.245, loss_g=1.6] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=457, loss_d=0.342, loss_g=1.49]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=458, loss_d=0.262, loss_g=1.63]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=459, loss_d=0.136, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=460, loss_d=0.165, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=461, loss_d=0.114, loss_g=2.06] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=462, loss_d=0.243, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=463, loss_d=0.238, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=464, loss_d=0.238, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=465, loss_d=0.238, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=466, loss_d=0.236, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=467, loss_d=0.442, loss_g=1.17]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=468, loss_d=0.329, loss_g=1.38]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=469, loss_d=0.298, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=470, loss_d=0.309, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=471, loss_d=0.212, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=472, loss_d=0.228, loss_g=1.64]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=473, loss_d=0.217, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=474, loss_d=0.181, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=475, loss_d=0.227, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=476, loss_d=0.238, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=477, loss_d=0.225, loss_g=1.62]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=478, loss_d=0.0639, loss_g=2.08]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=479, loss_d=0.0936, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=480, loss_d=0.191, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=481, loss_d=0.355, loss_g=1.4] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=482, loss_d=0.372, loss_g=1.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=483, loss_d=0.232, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=484, loss_d=0.27, loss_g=1.61] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=485, loss_d=0.249, loss_g=1.49]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=486, loss_d=0.248, loss_g=1.5]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=487, loss_d=0.245, loss_g=1.52]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=488, loss_d=0.243, loss_g=1.53]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=489, loss_d=0.253, loss_g=1.52]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=490, loss_d=0.26, loss_g=1.53] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=491, loss_d=0.241, loss_g=1.55]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=492, loss_d=0.241, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=493, loss_d=0.258, loss_g=1.54]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=494, loss_d=0.238, loss_g=1.55]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=495, loss_d=0.24, loss_g=1.56] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=496, loss_d=0.239, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=497, loss_d=0.237, loss_g=1.55]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=498, loss_d=0.238, loss_g=1.56]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=499, loss_d=0.237, loss_g=1.55]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=500, loss_d=0.344, loss_g=1.55]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 126/126 [01:12<00:00,  1.75it/s, epoch=1, loss_d=0.384, loss_g=4.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=2, loss_d=0.37, loss_g=2.67] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=3, loss_d=0.439, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=4, loss_d=0.435, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=5, loss_d=0.445, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=6, loss_d=0.432, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=7, loss_d=0.439, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=8, loss_d=0.438, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=9, loss_d=0.437, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=10, loss_d=0.386, loss_g=2.13]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=11, loss_d=0.402, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=12, loss_d=0.389, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=13, loss_d=0.369, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=14, loss_d=0.357, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=15, loss_d=0.341, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=16, loss_d=0.32, loss_g=2.01] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=17, loss_d=0.325, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=18, loss_d=0.293, loss_g=2.04]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=19, loss_d=0.238, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=20, loss_d=0.335, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=21, loss_d=0.263, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=22, loss_d=0.206, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=23, loss_d=0.17, loss_g=2.29] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=24, loss_d=0.19, loss_g=2.31] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=25, loss_d=0.222, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=26, loss_d=0.17, loss_g=2.33] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=27, loss_d=0.18, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=28, loss_d=0.177, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=29, loss_d=0.156, loss_g=2.46]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=30, loss_d=0.0971, loss_g=2.45]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=31, loss_d=0.25, loss_g=2.19] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=32, loss_d=0.204, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=33, loss_d=0.139, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=34, loss_d=0.111, loss_g=2.5] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=35, loss_d=0.144, loss_g=2.42]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=36, loss_d=0.145, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=37, loss_d=0.164, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=38, loss_d=0.121, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=39, loss_d=0.146, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=40, loss_d=0.133, loss_g=2.35]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=41, loss_d=0.153, loss_g=2.37]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=42, loss_d=0.177, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=43, loss_d=0.165, loss_g=2.38]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=44, loss_d=0.148, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=45, loss_d=0.107, loss_g=2.42]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=46, loss_d=0.111, loss_g=2.38]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=47, loss_d=0.11, loss_g=2.38] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=48, loss_d=0.103, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=49, loss_d=0.155, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=50, loss_d=0.118, loss_g=2.43]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=51, loss_d=0.215, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=52, loss_d=0.155, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=53, loss_d=0.143, loss_g=2.35]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=54, loss_d=0.102, loss_g=2.4] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=55, loss_d=0.148, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=56, loss_d=0.12, loss_g=2.36] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=57, loss_d=0.0942, loss_g=2.41]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=58, loss_d=0.15, loss_g=2.46] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=59, loss_d=0.168, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=60, loss_d=0.317, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=61, loss_d=0.319, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=62, loss_d=0.289, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=63, loss_d=0.32, loss_g=1.95] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=64, loss_d=0.312, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=65, loss_d=0.303, loss_g=1.95]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=66, loss_d=0.249, loss_g=2.09]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=67, loss_d=0.242, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=68, loss_d=0.308, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=69, loss_d=0.3, loss_g=2.01]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=70, loss_d=0.145, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=71, loss_d=0.327, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=72, loss_d=0.185, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=73, loss_d=0.155, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=74, loss_d=0.126, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=75, loss_d=0.125, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=76, loss_d=0.115, loss_g=2.4] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=77, loss_d=0.112, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=78, loss_d=0.117, loss_g=2.35]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=79, loss_d=0.11, loss_g=2.33] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=80, loss_d=0.14, loss_g=2.29] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=81, loss_d=0.102, loss_g=2.43]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=82, loss_d=0.0954, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=83, loss_d=0.191, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=84, loss_d=0.311, loss_g=1.96]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=85, loss_d=0.305, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=86, loss_d=0.313, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=87, loss_d=0.322, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=88, loss_d=0.315, loss_g=1.9] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=89, loss_d=0.127, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=90, loss_d=0.0921, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=91, loss_d=0.26, loss_g=2.03] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=92, loss_d=0.43, loss_g=1.85] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=93, loss_d=0.371, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=94, loss_d=0.247, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=95, loss_d=0.207, loss_g=2.04]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=96, loss_d=0.181, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=97, loss_d=0.185, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=98, loss_d=0.167, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=99, loss_d=0.314, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=100, loss_d=0.357, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=101, loss_d=0.359, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=102, loss_d=0.377, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=103, loss_d=0.352, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=104, loss_d=0.327, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=105, loss_d=0.39, loss_g=1.63] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=106, loss_d=0.342, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=107, loss_d=0.126, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=108, loss_d=0.184, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=109, loss_d=0.236, loss_g=2.11]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=110, loss_d=0.27, loss_g=1.96] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=111, loss_d=0.328, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=112, loss_d=0.358, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=113, loss_d=0.31, loss_g=1.87] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=114, loss_d=0.317, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=115, loss_d=0.293, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=116, loss_d=0.253, loss_g=2]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=117, loss_d=0.244, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=118, loss_d=0.149, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=119, loss_d=0.101, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=120, loss_d=0.183, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=121, loss_d=0.332, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=122, loss_d=0.33, loss_g=1.79] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=123, loss_d=0.307, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=124, loss_d=0.372, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=125, loss_d=0.312, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=126, loss_d=0.236, loss_g=1.89]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=127, loss_d=0.294, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=128, loss_d=0.301, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=129, loss_d=0.266, loss_g=2.03]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=130, loss_d=0.203, loss_g=2]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=131, loss_d=0.0371, loss_g=2.35]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=132, loss_d=0.0676, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=133, loss_d=0.156, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=134, loss_d=0.037, loss_g=2.34] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=135, loss_d=0.0423, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=136, loss_d=0.0299, loss_g=2.4] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=137, loss_d=0.0904, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=138, loss_d=0.1, loss_g=2.34]   \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=139, loss_d=0.23, loss_g=1.82] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=140, loss_d=0.225, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=141, loss_d=0.299, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=142, loss_d=0.517, loss_g=1.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=143, loss_d=0.465, loss_g=1.36]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=144, loss_d=0.365, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=145, loss_d=0.194, loss_g=2.04]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=146, loss_d=0.35, loss_g=1.72] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=147, loss_d=0.47, loss_g=1.18] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=148, loss_d=0.311, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=149, loss_d=0.143, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=150, loss_d=0.0336, loss_g=2.48]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=151, loss_d=0.102, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=152, loss_d=0.291, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=153, loss_d=0.137, loss_g=2.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=154, loss_d=0.14, loss_g=2.15] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=155, loss_d=0.106, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=156, loss_d=0.0365, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=157, loss_d=0.128, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=158, loss_d=0.107, loss_g=2.15]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=159, loss_d=0.0582, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=160, loss_d=0.023, loss_g=2.31] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=161, loss_d=0.066, loss_g=2.28] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=162, loss_d=0.0272, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=163, loss_d=0.0184, loss_g=2.4] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=164, loss_d=0.0255, loss_g=2.32] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=165, loss_d=0.0027, loss_g=2.36] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=166, loss_d=0.0537, loss_g=2.34] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=167, loss_d=0.415, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=168, loss_d=0.218, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=169, loss_d=0.225, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=170, loss_d=0.076, loss_g=2.29] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=171, loss_d=0.035, loss_g=2.3]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=172, loss_d=0.0323, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=173, loss_d=0.0154, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=174, loss_d=0.0402, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=175, loss_d=0.0746, loss_g=2.28] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=176, loss_d=0.108, loss_g=2.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=177, loss_d=0.0143, loss_g=2.37] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=178, loss_d=0.00455, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=179, loss_d=0.00158, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=180, loss_d=0.00244, loss_g=2.36]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=181, loss_d=0.0354, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=182, loss_d=0.114, loss_g=2.28] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=183, loss_d=0.0982, loss_g=2.4]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=184, loss_d=0.0484, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=185, loss_d=0.00958, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=186, loss_d=0.0348, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=187, loss_d=0.0701, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=188, loss_d=0.0228, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=189, loss_d=0.00592, loss_g=2.39]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=190, loss_d=0.00563, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=191, loss_d=0.0745, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=192, loss_d=0.141, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=193, loss_d=0.026, loss_g=2.32] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=194, loss_d=0.00652, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.64it/s, epoch=195, loss_d=0.00705, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=196, loss_d=0.000585, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=197, loss_d=0.00254, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=198, loss_d=0.000456, loss_g=2.3]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=199, loss_d=0.224, loss_g=1.99]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=200, loss_d=0.26, loss_g=1.87] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=201, loss_d=0.266, loss_g=1.82]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=202, loss_d=0.132, loss_g=2.16]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=203, loss_d=0.0189, loss_g=2.3] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=204, loss_d=0.0141, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=205, loss_d=0.0144, loss_g=2.3]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=206, loss_d=0.061, loss_g=2.35] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=207, loss_d=0.0632, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=208, loss_d=0.24, loss_g=1.85] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=209, loss_d=0.352, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=210, loss_d=0.213, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=211, loss_d=0.268, loss_g=1.85]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=212, loss_d=0.238, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=213, loss_d=0.0219, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=214, loss_d=0.0284, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=215, loss_d=0.0312, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=216, loss_d=0.0395, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=217, loss_d=0.0679, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=218, loss_d=0.0253, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=219, loss_d=0.246, loss_g=1.84]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=220, loss_d=0.289, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=221, loss_d=0.221, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=222, loss_d=0.199, loss_g=1.91]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=223, loss_d=0.178, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=224, loss_d=0.0193, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=225, loss_d=0.00937, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=226, loss_d=0.0435, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=227, loss_d=0.0328, loss_g=2.29] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=228, loss_d=0.0455, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=229, loss_d=0.0339, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=230, loss_d=0.0217, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=231, loss_d=0.000985, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=232, loss_d=0.00375, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=233, loss_d=0.00082, loss_g=2.28] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=234, loss_d=0.00418, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=235, loss_d=0.00483, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=236, loss_d=0.00315, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=237, loss_d=0.00633, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=238, loss_d=0.0101, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=239, loss_d=0.00739, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=240, loss_d=0.00412, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=241, loss_d=0.0735, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=242, loss_d=0.267, loss_g=2.1]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=243, loss_d=0.229, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=244, loss_d=0.224, loss_g=1.98]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=245, loss_d=0.214, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=246, loss_d=0.00503, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=247, loss_d=0.004, loss_g=2.28]  \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=248, loss_d=0.00199, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=249, loss_d=0.101, loss_g=2.21] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=250, loss_d=0.00815, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=251, loss_d=0.0697, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=252, loss_d=0.00927, loss_g=2.33]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=253, loss_d=0.0012, loss_g=2.28] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=254, loss_d=0.0137, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=255, loss_d=0.00433, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=256, loss_d=0.262, loss_g=2.04]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=257, loss_d=0.261, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=258, loss_d=0.235, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=259, loss_d=0.164, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=260, loss_d=0.0387, loss_g=2.34]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=261, loss_d=0.151, loss_g=2.01]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=262, loss_d=0.0847, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=263, loss_d=0.0148, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=264, loss_d=0.0374, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=265, loss_d=0.0282, loss_g=2.27] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=266, loss_d=0.185, loss_g=1.92]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=267, loss_d=0.254, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=268, loss_d=0.162, loss_g=2.05]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=269, loss_d=0.134, loss_g=2.02]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=270, loss_d=0.0144, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=271, loss_d=0.0029, loss_g=2.32] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=272, loss_d=0.00342, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=273, loss_d=0.0142, loss_g=2.25] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=274, loss_d=0.0592, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=275, loss_d=0.106, loss_g=2.2]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=276, loss_d=0.0529, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=277, loss_d=0.0996, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=278, loss_d=0.503, loss_g=1.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=279, loss_d=0.309, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=280, loss_d=0.207, loss_g=1.93]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=281, loss_d=0.218, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=282, loss_d=0.274, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=283, loss_d=0.281, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=284, loss_d=0.223, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=285, loss_d=0.211, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=286, loss_d=0.214, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=287, loss_d=0.163, loss_g=1.92]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=288, loss_d=0.00906, loss_g=2.3]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=289, loss_d=0.000443, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=290, loss_d=0.00225, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=291, loss_d=0.00108, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=292, loss_d=0.0569, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=293, loss_d=0.412, loss_g=1.59]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=294, loss_d=0.281, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=295, loss_d=0.242, loss_g=1.79]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=296, loss_d=0.193, loss_g=2.09]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=297, loss_d=0.223, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=298, loss_d=0.219, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=299, loss_d=0.219, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=300, loss_d=0.126, loss_g=2]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=301, loss_d=0.218, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=302, loss_d=0.219, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=303, loss_d=0.392, loss_g=1.71]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=304, loss_d=0.0815, loss_g=2.16]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=305, loss_d=0.0105, loss_g=2.25] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=306, loss_d=0.0118, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=307, loss_d=0.0449, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=308, loss_d=0.00518, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=309, loss_d=0.0112, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=310, loss_d=0.00488, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=311, loss_d=0.0917, loss_g=2.24] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=312, loss_d=0.219, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=313, loss_d=0.229, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=314, loss_d=0.19, loss_g=1.86] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=315, loss_d=0.228, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=316, loss_d=0.283, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=317, loss_d=0.195, loss_g=1.88]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=318, loss_d=0.212, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=319, loss_d=0.216, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=320, loss_d=0.207, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=321, loss_d=0.214, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=322, loss_d=0.224, loss_g=1.81]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=323, loss_d=0.292, loss_g=1.75]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=324, loss_d=0.398, loss_g=1.41]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=325, loss_d=0.437, loss_g=1.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=326, loss_d=0.289, loss_g=1.65]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=327, loss_d=0.147, loss_g=1.99]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=328, loss_d=0.218, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=329, loss_d=0.211, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=330, loss_d=0.2, loss_g=1.78]  \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=331, loss_d=0.168, loss_g=1.87]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=332, loss_d=0.383, loss_g=1.68]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=333, loss_d=0.343, loss_g=1.58]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=334, loss_d=0.248, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=335, loss_d=0.228, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=336, loss_d=0.0639, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=337, loss_d=0.0311, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=338, loss_d=0.0111, loss_g=2.28]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=339, loss_d=0.00117, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=340, loss_d=0.000894, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=341, loss_d=0.00267, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=342, loss_d=0.000977, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=343, loss_d=0.00293, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.65it/s, epoch=344, loss_d=0.0472, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=345, loss_d=0.0467, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=346, loss_d=0.00149, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=347, loss_d=0.107, loss_g=2.16]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=348, loss_d=0.0204, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=349, loss_d=0.0299, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=350, loss_d=0.00322, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=351, loss_d=0.0108, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=352, loss_d=0.0019, loss_g=2.25] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=353, loss_d=0.00933, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=354, loss_d=0.14, loss_g=2.12] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=355, loss_d=0.253, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=356, loss_d=0.316, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=357, loss_d=0.0742, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=358, loss_d=0.0303, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=359, loss_d=0.0752, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=360, loss_d=0.0174, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=361, loss_d=0.00522, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=362, loss_d=0.00181, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=363, loss_d=0.0102, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=364, loss_d=0.00396, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=365, loss_d=0.135, loss_g=2.05] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=366, loss_d=0.0323, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=367, loss_d=0.0176, loss_g=2.24] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=368, loss_d=0.0797, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=369, loss_d=0.014, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=370, loss_d=0.0205, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=371, loss_d=0.00538, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=372, loss_d=0.00278, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=373, loss_d=0.0355, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=374, loss_d=0.117, loss_g=2.14] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=375, loss_d=0.031, loss_g=2.26] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=376, loss_d=0.00331, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=377, loss_d=0.00163, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=378, loss_d=0.00641, loss_g=2.29]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=379, loss_d=0.031, loss_g=2.24] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=380, loss_d=0.0148, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=381, loss_d=0.0443, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=382, loss_d=0.038, loss_g=2.24] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=383, loss_d=0.0279, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=384, loss_d=0.0124, loss_g=2.24] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=385, loss_d=0.0105, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=386, loss_d=0.175, loss_g=2.04]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=387, loss_d=0.111, loss_g=2.17] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=388, loss_d=0.00403, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=389, loss_d=0.00337, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=390, loss_d=0.0351, loss_g=2.22]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=391, loss_d=0.294, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=392, loss_d=0.23, loss_g=1.67] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=393, loss_d=0.201, loss_g=1.77]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=394, loss_d=0.278, loss_g=1.73]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=395, loss_d=0.0764, loss_g=2.12]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=396, loss_d=0.00369, loss_g=2.31]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=397, loss_d=0.00389, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=398, loss_d=0.0922, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=399, loss_d=0.0606, loss_g=2.32]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=400, loss_d=0.0429, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=401, loss_d=0.002, loss_g=2.23]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=402, loss_d=0.0919, loss_g=2.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=403, loss_d=0.0178, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=404, loss_d=0.0738, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=405, loss_d=0.02, loss_g=2.23]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=406, loss_d=0.0164, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=407, loss_d=0.0195, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=408, loss_d=0.053, loss_g=2.21]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=409, loss_d=0.0584, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=410, loss_d=0.0193, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=411, loss_d=0.00543, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=412, loss_d=0.0063, loss_g=2.25] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=413, loss_d=0.0104, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=414, loss_d=0.000855, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=415, loss_d=0.034, loss_g=2.2]   \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=416, loss_d=0.0127, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=417, loss_d=0.00468, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=418, loss_d=0.0529, loss_g=2.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=419, loss_d=0.0189, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=420, loss_d=0.0618, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=421, loss_d=0.0291, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=422, loss_d=0.029, loss_g=2.21] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=423, loss_d=0.0198, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=424, loss_d=0.00316, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=425, loss_d=0.00606, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=426, loss_d=0.0531, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=427, loss_d=0.0734, loss_g=2.18]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=428, loss_d=0.127, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=429, loss_d=0.0134, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=430, loss_d=0.00947, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=431, loss_d=0.00827, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=432, loss_d=0.00153, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=433, loss_d=0.00261, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=434, loss_d=0.0167, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=435, loss_d=0.00537, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=436, loss_d=0.00179, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=437, loss_d=0.00204, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=438, loss_d=0.000706, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=439, loss_d=0.0978, loss_g=2.12] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=440, loss_d=0.149, loss_g=2.08] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=441, loss_d=0.219, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=442, loss_d=0.207, loss_g=1.97]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=443, loss_d=0.224, loss_g=1.8] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=444, loss_d=0.302, loss_g=1.66]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=445, loss_d=0.359, loss_g=1.61]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=446, loss_d=0.219, loss_g=1.72]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=447, loss_d=0.199, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=448, loss_d=0.175, loss_g=1.83]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=449, loss_d=0.205, loss_g=1.76]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=450, loss_d=0.198, loss_g=1.74]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=451, loss_d=0.191, loss_g=1.78]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=452, loss_d=0.0712, loss_g=2.08]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=453, loss_d=0.0179, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=454, loss_d=0.0125, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=455, loss_d=0.0412, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=456, loss_d=0.0275, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=457, loss_d=0.0706, loss_g=2.17] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=458, loss_d=0.0156, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=459, loss_d=0.15, loss_g=2]    \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=460, loss_d=0.0238, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=461, loss_d=0.00717, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=462, loss_d=0.00722, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=463, loss_d=0.00439, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=464, loss_d=0.000514, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=465, loss_d=0.00124, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=466, loss_d=0.00975, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=467, loss_d=0.00669, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=468, loss_d=0.17, loss_g=2.04]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=469, loss_d=0.0555, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=470, loss_d=0.0565, loss_g=2.2] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=471, loss_d=0.0375, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=472, loss_d=0.0568, loss_g=2.2]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=473, loss_d=0.00802, loss_g=2.25]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=474, loss_d=0.00682, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=475, loss_d=0.0253, loss_g=2.19] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=476, loss_d=0.043, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=477, loss_d=0.0137, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=478, loss_d=0.128, loss_g=2.23]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=479, loss_d=0.0576, loss_g=2.21] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=480, loss_d=0.0666, loss_g=2.19]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=481, loss_d=0.0181, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=482, loss_d=0.00689, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=483, loss_d=0.00444, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=484, loss_d=0.00217, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=485, loss_d=0.0017, loss_g=2.22]  \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=486, loss_d=0.109, loss_g=2.14]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=487, loss_d=0.0266, loss_g=2.27]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=488, loss_d=0.000477, loss_g=2.23]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=489, loss_d=0.000997, loss_g=2.22]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=490, loss_d=0.00322, loss_g=2.21]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=491, loss_d=0.0068, loss_g=2.23] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=492, loss_d=0.0031, loss_g=2.22] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=493, loss_d=0.0627, loss_g=2.24]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=494, loss_d=0.0404, loss_g=2.26]\n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=495, loss_d=0.00108, loss_g=2.21] \n",
            "100%|██████████| 126/126 [01:16<00:00,  1.66it/s, epoch=496, loss_d=0.126, loss_g=2.13]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=497, loss_d=0.025, loss_g=2.19] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=498, loss_d=0.014, loss_g=2.19] \n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=499, loss_d=0.00314, loss_g=2.2]\n",
            "100%|██████████| 126/126 [01:15<00:00,  1.66it/s, epoch=500, loss_d=0.0236, loss_g=2.2]  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import gc\n",
        "import torch\n",
        "import math\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "# from torchsummary import summary\n",
        "# from torchmetrics import PeakSignalNoiseRatio\n",
        "from skimage import color\n",
        "from skimage.metrics import structural_similarity\n",
        "from cyclegan_tranformer import Generator\n",
        "from Utils import save_checkpoint, load_checkpoint\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "dataset_name = \"brats\"  \n",
        "\n",
        "path = \"Results\"\n",
        "checkpoint = \"Results/genb.pth.tar\"\n",
        "save_path = f\"Results/Testing/{dataset_name}\"\n",
        "TEST_DIR = 'datasets/brats/test/'\n",
        "IMAGE_WIDTH = 256\n",
        "IMAGE_HEIGHT = 256\n",
        "\n",
        "\n",
        "gpu_index = 3  # for 4th GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(f\"cuda:{gpu_index}\")\n",
        "    print(f\"Selected GPU: {gpu_index}\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "\n",
        "\n",
        "\n",
        "def masking(a, b):\n",
        "    l_top = l_bottom = 0\n",
        "    a = a[0]\n",
        "    b = b[0]\n",
        "\n",
        "    for i in range(a.shape[1]):\n",
        "        if torch.sum(a[:, i, :]) != 0:\n",
        "            break\n",
        "        l_top += 1\n",
        "\n",
        "    for i in range(a.shape[1]):\n",
        "        if torch.sum(a[:, a.shape[1] - i - 1, :]) != 0:\n",
        "            break\n",
        "        l_bottom += 1\n",
        "\n",
        "    b[:, :l_top, :] = 0\n",
        "    b[:, b.shape[1] - l_bottom:, :] = 0\n",
        "\n",
        "    return a, b\n",
        "\n",
        "\n",
        "def PSNR_SSIM(orig_img, gen_img):\n",
        "    gray_orig_img = color.rgb2gray(orig_img)\n",
        "    gray_gen_img = color.rgb2gray(gen_img)\n",
        "\n",
        "    mse = np.mean((gray_orig_img - gray_gen_img) ** 2)\n",
        "    if mse == 0:\n",
        "        psnr = 100\n",
        "    else:\n",
        "        max_pixel = 1.0\n",
        "        psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n",
        "\n",
        "    ssim = structural_similarity(gray_orig_img, gray_gen_img, multichannel=False, data_range=1.0)\n",
        "\n",
        "    return round(psnr, 3), round(ssim, 3)\n",
        "\n",
        "\n",
        "\n",
        "gen = Generator(width=IMAGE_WIDTH, height=IMAGE_HEIGHT).to(DEVICE)\n",
        "# summary(gen, (3, 256, 256))\n",
        "\n",
        "load_checkpoint(checkpoint, gen, None, None)\n",
        "print(\"Checkpoint loaded\")\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=IMAGE_WIDTH, height=IMAGE_HEIGHT),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_dataset = ABDataset(\n",
        "    # root_a=TEST_DIR, transform=transforms\n",
        "    root_a=TEST_DIR+\"/t1c_r\", transform=transforms\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "loop = tqdm(val_loader, leave=True)\n",
        "psnr_values = []\n",
        "ssim_values = []\n",
        "mse_values = []\n",
        "\n",
        "print(\"val_loader\", len(val_loader))\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# print(\"Before loop\")\n",
        "for idx, image in enumerate(loop):\n",
        "    image = image.to(DEVICE)\n",
        "    # print(\"Inside loop1\")\n",
        "    with torch.cuda.amp.autocast():\n",
        "        # print(\"Inside loop2\")\n",
        "        # print(\"idx\", idx)\n",
        "        \n",
        "        gen_image = gen(image)\n",
        "        image, gen_image = masking(image*0.5+0.5, gen_image*0.5+0.5)\n",
        "\n",
        "        save_image(gen_image, f\"{save_path}/{idx}_fake.png\")\n",
        "        save_image(image, f\"{save_path}/{idx}_real.png\")\n",
        "\n",
        "        image = image.permute(1, 2, 0).detach().cpu().numpy()\n",
        "        gen_image = gen_image.permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "        psnr_values.append(PSNR_SSIM(image, gen_image)[0])\n",
        "        ssim_values.append(PSNR_SSIM(image, gen_image)[1])\n",
        "        \n",
        "        # mse = torch.mean((gen_image - image)**2).item()\n",
        "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).to(DEVICE)\n",
        "        gen_image_tensor = torch.from_numpy(gen_image).permute(2, 0, 1).to(DEVICE)\n",
        "        mse = torch.mean((gen_image_tensor - image_tensor)**2).item()\n",
        "        mse_values.append(mse)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "metrics = [\n",
        "    round(sum(psnr_values) / len(val_loader), 3),\n",
        "    round(sum(ssim_values) / len(val_loader), 3),\n",
        "    round((end - start) / len(val_loader), 3)\n",
        "]\n",
        "\n",
        "f = open(f\"{path}/Results {dataset_name}.txt\", 'w')\n",
        "f.write(f\"Testing PSNR :{metrics[0]} dB\\n\")\n",
        "f.write(f\"Testing SSIM :{metrics[1]}\\n\")\n",
        "f.write(f\"Single image time: {metrics[2]} seconds\\n\")\n",
        "\n",
        "print(\"Testing PSNR\" ,metrics[0])\n",
        "print(\"Testing SSIM\" ,metrics[1])\n",
        "mean_mse = round(sum(mse_values) / len(mse_values), 3)\n",
        "print(f\"Mean MSE: {mean_mse}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
